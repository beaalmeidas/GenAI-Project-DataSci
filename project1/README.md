# Chat RAG com Login e Persist√™ncia de Dados

Um sistema de chat inteligente constru√≠do com Streamlit e Langchain que permite aos usu√°rios realizar upload de documentos e realizar perguntas sobre o conte√∫do, com suporte a contas de usu√°rio, hist√≥rico de conversas e persist√™ncia de arquivos.

## Vis√£o Geral

Este projeto implementa o padr√£o RAG (Retrieval-Augmented Generation) para criar um chatbot que responde perguntas com base em um conjunto de documentos fornecido pelo usu√°rio. A aplica√ß√£o √© totalmente interativa, com uma interface web constru√≠da em Streamlit, e possui um sistema de backend robusto para gerenciar usu√°rios, conversas e os √≠ndices vetoriais de cada um.

---

## ‚ú® Funcionalidades Principais

* **Autentica√ß√£o de Usu√°rio:** Sistema de cria√ß√£o de conta e login para garantir que os dados de cada usu√°rio sejam privados e persistentes.
* **Upload de M√∫ltiplos Formatos:** Suporte para upload de arquivos `.pdf`, `.docx`, `.xlsx`, `.csv`, e `.txt`.
* **Persist√™ncia de Dados por Usu√°rio:**
    * **Hist√≥rico de Chat:** As conversas s√£o salvas em um banco de dados SQLite e recarregadas a cada login.
    * **Base de Conhecimento:** Os documentos processados s√£o convertidos em vetores e armazenados em um √≠ndice FAISS dedicado para cada usu√°rio.
* **Gerenciamento de Arquivos:** Os usu√°rios podem visualizar e remover os arquivos que j√° foram carregados, com a base de conhecimento sendo atualizada de acordo.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **[Streamlit](https://streamlit.io/)**
* **Python 3.12+**
* **LLM e RAG:** [Ollama](https://ollama.com/) com o modelo `llama3` e [Langchain](https://www.langchain.com/).
* **Banco de Dados Relacional:** [SQLite](https://www.sqlite.org/)
* **Banco de Dados Vetorial:** [Facebook AI Similarity Search (FAISS)](https://github.com/facebookresearch/faiss)
* **Modelo de Embeddings:** `nomic-ai/nomic-embed-text-v1` da [Hugging Face](https://huggingface.co/nomic-ai/nomic-embed-text-v1)

---

## üöÄ Instala√ß√£o e Execu√ß√£o

Siga os passos abaixo para configurar e rodar o projeto localmente.

### 1. Pr√©-requisitos

* **Python 3.12 ou superior:** [Instalar Python](https://www.python.org/downloads/)
* **Git:** Para clonar o reposit√≥rio.
* **Ollama:** A aplica√ß√£o utiliza o Ollama para rodar o modelo Llama 3 localmente.
    * [Instale o Ollama](https://ollama.com/).
    * Ap√≥s a instala√ß√£o, puxe o modelo `llama3` com o comando:
        ```bash
        ollama pull llama3
        ```
    * Certifique-se de que o Ollama esteja em execu√ß√£o antes de iniciar a aplica√ß√£o Streamlit.

### 2. Clone o Reposit√≥rio

```bash
git clone https://github.com/beaalmeidas/GenAI-Project-DataSci
cd project1
```

### 3. Crie um Ambiente Virtual e Instale as Depend√™ncias
```bash
# Criar o ambiente virtual
python3 -m venv venv

# Ativar o ambiente virtual
venv\Scripts\activate           # <- Windows

source venv/bin/activate        # <- macOS/Linux
```

Agora, instale todas as depend√™ncias com:

```bash
pip install -r requirements.txt
```

## 4. Execute a Aplica√ß√£o
Com o ambiente virtual ativado, execute o Ollama e inicie a aplica√ß√£o Streamlit:

<h2> Iniciar llama3 </h2>

```bash
ollama serve
```

<h2> Iniciar aplica√ß√£o Streamlit</h2>

```bash
streamlit run app.py
```

A aplica√ß√£o dever√° abrir automaticamente no seu navegador padr√£o.


## üìñ Como Usar

1. **Crie uma Conta:** Na barra lateral, insira um nome de usu√°rio e senha e clique em "Criar Conta".


2. **Fa√ßa Login:** Use as mesmas credenciais para fazer o login.


3. **Fa√ßa Upload de Arquivos:** Na barra lateral, selecione um ou mais documentos e clique no bot√£o "Processar Arquivos".

4. **Aguarde o Processamento:** A aplica√ß√£o ir√° extrair o texto, criar os embeddings e salvar sua base de conhecimento.

5. **Converse:** Com os arquivos processados, v√° para a √°rea de chat principal, digite sua pergunta e clique em "Enviar".

6. **Gerencie seus Arquivos:** Na barra lateral, voc√™ pode ver a lista de arquivos carregados e remover qualquer um deles clicando no √≠cone de lixeira.
